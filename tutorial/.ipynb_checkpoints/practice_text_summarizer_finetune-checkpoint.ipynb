{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                  date  \\\n",
       "0    Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "1     Daisy Mowke  03 Aug 2017,Thursday   \n",
       "2  Arshiya Chopra  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "\n",
       "                                               ctext  \n",
       "0  The Daman and Diu administration on Wednesday ...  \n",
       "1  From her special numbers to TV?appearances, Bo...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../input/news_summary.csv\", encoding=\"latin-1\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4514, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>summarize: The Daman and Diu administration on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>summarize: From her special numbers to TV?appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>summarize: The Indira Gandhi Institute of Medi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "\n",
       "                                               ctext  \n",
       "0  summarize: The Daman and Diu administration on...  \n",
       "1  summarize: From her special numbers to TV?appe...  \n",
       "2  summarize: The Indira Gandhi Institute of Medi...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"ctext\"]]\n",
    "df.ctext = \"summarize: \" + df.ctext\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = str(df.text[0])\n",
    "text = \" \".join(text.split())\n",
    "\n",
    "ctext = str(df.ctext[0])\n",
    "ctext = \" \".join(ctext.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[21603,    10,    37,   878,   348,    11,  2043,    76,  3602,    30,\n",
      "          2875,    28,    26,    60,   210,     3,     9, 15646,    24,  1380,\n",
      "           887,   871,    12,  6177,     3,  9782, 10193,    30,  5069,  6976,\n",
      "           227,     8,   455,     3, 18728,     3,     9,   223,  8058,    45,\n",
      "          1652,    11,    47,     3, 23830,  3943,    30,   569,   783,     5,\n",
      "           634,  7021,  9964,    58,     7,  3602,    47,  5241,    12, 10742,\n",
      "           441,   997,   716,    13,    19, 17180,     8, 15646,    24,   263,\n",
      "            34, 29701,    21,   165,   871,    12,  4036,  2922,   157,     7,\n",
      "          6111,   232,  2618,    44,  6940,     5,    58,   196,    17,    65,\n",
      "           118,  1500,    12,  4036,     8,  3994,    13,  2922,   157,     7,\n",
      "          6111,   232,  2618,    30,  1660,  4306,    86,    48,  2135,     6,\n",
      "            66,  6036,    87, 10521,  1522,  2367,   539,    11,  4036,     8,\n",
      "          3994,  6018,   120,    44,     3,     9,  3255,    97,   213,    77,\n",
      "            66,     8,  9360,   871,  1522,  6177,     3,  9782, 10193,    12,\n",
      "            70,  6976,     6,    58,     8,   455,     6,  4683,    30,  1660,\n",
      "           209,    57, 20402,  2026,    15,    17, 16738,     6, 21108, 15852,\n",
      "            41,  6075,    29,    15,    40,   201,   141,   243,     5,  3696,\n",
      "           766,    24,   150,    80, 26205,    26,   828,     6,    46, 11364,\n",
      "           934,    47,    12,    36,  1622,    12,     8,   789,     8,   416,\n",
      "          2272,     5,   634,   192, 16807,     3,    58,    80, 15579,    53,\n",
      "             8,  5216,    13,  2922,   157,     7,  6111,   232,  2618,    41,\n",
      "         17068,    61,    11,     8,   119, 14510,    53,     8, 12871,    41,\n",
      "          3535,    61,     3,    58,   130,  4683,    57,     8,   878,   348,\n",
      "            11,  2043,    76,  3602,     3,     9,   239,  3943,     5,    37,\n",
      "         15646,    47,     3, 28032,   190,     3,     9,    80,    18,   747,\n",
      "           455,  4683,  1480,    16,     8,  2272,    57,     8,     3,  6675,\n",
      "            58,     7,  3066,    13,  4231,    11,  6601,  5139,     7,     5,\n",
      "            58,   634, 15646,    19, 15708,     5,   290,    33,  3952,    23,\n",
      "          5499,  2197,  1381,     5,   571,    54,     8,   789, 19810,   113,\n",
      "            27,   225,  6177,     3,    52,     9, 29392,    12,    58,   101,\n",
      "           225,  1961,     8, 18655,    13,     3,     9,  6940,    58,    46,\n",
      "          2314,  1219, 18528,  5627,  5324,  2283,    16,     8,   239,     5,\n",
      "           451, 12191,    12,    36,  4313,     5,   634,  2103,    47,  4683,\n",
      "            30,   878,   348,    11,  2043,    76, 13176,    11,  1798, 30812,\n",
      "           234,  6323,  6110,  1329,  1793,    26,     9,   115,  1024,    23,\n",
      "          2709,  1625,    58,     7,  2212,     6,  2836,   243,     5,   448,\n",
      "          1639,     7,  6111,   232,  2618,     6,     3,     9,  5216,    13,\n",
      "             8,  6235,   344, 10740,    11, 14033,     6,    19,    80,    13,\n",
      "           633, 18528, 28585,    11, 12898,     7,    24,    33,   150,  1200,\n",
      "             3, 24092,    13,  1045,     6,   384, 12748,    68,    43,   582,\n",
      "          1339,    12,  3292,     3,  3003,  1225,   491, 31001,    15,     7,\n",
      "             5,  1570,  1412,     6,     8,   215,     3, 28065,  5536,    15,\n",
      "            26,    12,   579,    44,     8,  2969,     6,  9053,   107,    17,\n",
      "         26038,   180,  1343,   265,     7,  4721,   157,  1051,   122,   107,\n",
      "            41,  5249,   134,    61,  5752,  1290,  2618, 16332,     9,   122,\n",
      "           210,   144,   243,     8,  3994,   141,     3,    58, 16557, 11978,\n",
      "            58,    11,   225,    36,  9443,  5456,     3,    58,   235,  1822,\n",
      "         18528,  1543,    11,   619,    57,     8,  2620,     3,    35,     7,\n",
      "           107,  9249,    26,    16,    34,    58,     5,    37, 14348,    19,\n",
      "             8, 30981,  4208,    13,     8, 12346,     3, 28065,     5,  3612,\n",
      "             7,    17,   215,     6,   887,  6323,     7,    16,     8,  5073,\n",
      "            23,   789]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "source = tokenizer.batch_encode_plus(\n",
    "    [ctext], \n",
    "    max_length=512, \n",
    "    pad_to_max_length=True,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([512])\n",
      "tensor([21603,    10,    37,   878,   348,    11,  2043,    76,  3602,    30,\n",
      "         2875,    28,    26,    60,   210,     3,     9, 15646,    24,  1380,\n",
      "          887,   871,    12,  6177,     3,  9782, 10193,    30,  5069,  6976,\n",
      "          227,     8,   455,     3, 18728,     3,     9,   223,  8058,    45,\n",
      "         1652,    11,    47,     3, 23830,  3943,    30,   569,   783,     5,\n",
      "          634,  7021,  9964,    58,     7,  3602,    47,  5241,    12, 10742,\n",
      "          441,   997,   716,    13,    19, 17180,     8, 15646,    24,   263,\n",
      "           34, 29701,    21,   165,   871,    12,  4036,  2922,   157,     7,\n",
      "         6111,   232,  2618,    44,  6940,     5,    58,   196,    17,    65,\n",
      "          118,  1500,    12,  4036,     8,  3994,    13,  2922,   157,     7,\n",
      "         6111,   232,  2618,    30,  1660,  4306,    86,    48,  2135,     6,\n",
      "           66,  6036,    87, 10521,  1522,  2367,   539,    11,  4036,     8,\n",
      "         3994,  6018,   120,    44,     3,     9,  3255,    97,   213,    77,\n",
      "           66,     8,  9360,   871,  1522,  6177,     3,  9782, 10193,    12,\n",
      "           70,  6976,     6,    58,     8,   455,     6,  4683,    30,  1660,\n",
      "          209,    57, 20402,  2026,    15,    17, 16738,     6, 21108, 15852,\n",
      "           41,  6075,    29,    15,    40,   201,   141,   243,     5,  3696,\n",
      "          766,    24,   150,    80, 26205,    26,   828,     6,    46, 11364,\n",
      "          934,    47,    12,    36,  1622,    12,     8,   789,     8,   416,\n",
      "         2272,     5,   634,   192, 16807,     3,    58,    80, 15579,    53,\n",
      "            8,  5216,    13,  2922,   157,     7,  6111,   232,  2618,    41,\n",
      "        17068,    61,    11,     8,   119, 14510,    53,     8, 12871,    41,\n",
      "         3535,    61,     3,    58,   130,  4683,    57,     8,   878,   348,\n",
      "           11,  2043,    76,  3602,     3,     9,   239,  3943,     5,    37,\n",
      "        15646,    47,     3, 28032,   190,     3,     9,    80,    18,   747,\n",
      "          455,  4683,  1480,    16,     8,  2272,    57,     8,     3,  6675,\n",
      "           58,     7,  3066,    13,  4231,    11,  6601,  5139,     7,     5,\n",
      "           58,   634, 15646,    19, 15708,     5,   290,    33,  3952,    23,\n",
      "         5499,  2197,  1381,     5,   571,    54,     8,   789, 19810,   113,\n",
      "           27,   225,  6177,     3,    52,     9, 29392,    12,    58,   101,\n",
      "          225,  1961,     8, 18655,    13,     3,     9,  6940,    58,    46,\n",
      "         2314,  1219, 18528,  5627,  5324,  2283,    16,     8,   239,     5,\n",
      "          451, 12191,    12,    36,  4313,     5,   634,  2103,    47,  4683,\n",
      "           30,   878,   348,    11,  2043,    76, 13176,    11,  1798, 30812,\n",
      "          234,  6323,  6110,  1329,  1793,    26,     9,   115,  1024,    23,\n",
      "         2709,  1625,    58,     7,  2212,     6,  2836,   243,     5,   448,\n",
      "         1639,     7,  6111,   232,  2618,     6,     3,     9,  5216,    13,\n",
      "            8,  6235,   344, 10740,    11, 14033,     6,    19,    80,    13,\n",
      "          633, 18528, 28585,    11, 12898,     7,    24,    33,   150,  1200,\n",
      "            3, 24092,    13,  1045,     6,   384, 12748,    68,    43,   582,\n",
      "         1339,    12,  3292,     3,  3003,  1225,   491, 31001,    15,     7,\n",
      "            5,  1570,  1412,     6,     8,   215,     3, 28065,  5536,    15,\n",
      "           26,    12,   579,    44,     8,  2969,     6,  9053,   107,    17,\n",
      "        26038,   180,  1343,   265,     7,  4721,   157,  1051,   122,   107,\n",
      "           41,  5249,   134,    61,  5752,  1290,  2618, 16332,     9,   122,\n",
      "          210,   144,   243,     8,  3994,   141,     3,    58, 16557, 11978,\n",
      "           58,    11,   225,    36,  9443,  5456,     3,    58,   235,  1822,\n",
      "        18528,  1543,    11,   619,    57,     8,  2620,     3,    35,     7,\n",
      "          107,  9249,    26,    16,    34,    58,     5,    37, 14348,    19,\n",
      "            8, 30981,  4208,    13,     8, 12346,     3, 28065,     5,  3612,\n",
      "            7,    17,   215,     6,   887,  6323,     7,    16,     8,  5073,\n",
      "           23,   789])\n",
      "----------\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([512])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "source_ids = source[\"input_ids\"].squeeze()\n",
    "\n",
    "print(type(source_ids))\n",
    "print(source_ids.shape)\n",
    "print(source_ids)\n",
    "print(\"-\"*10)\n",
    "\n",
    "source_mask = source[\"attention_mask\"].squeeze()\n",
    "\n",
    "print(type(source_mask))\n",
    "print(source_mask.shape)\n",
    "print(source_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   37,  6863,    13,  3545, 30110,   878,   348,    11,  2043,    76,\n",
      "            65,     3,    52, 17943,    26,   165,   455,    24,   263,    34,\n",
      "         29701,    21,   887,    12,  6177,     3,  9782, 10193,    12,    70,\n",
      "          5069,  6976,    30,     8,  5333,    13,  2922,   157,     7,  6111,\n",
      "           232,  2618,    30,  1660,  4306,    37,  3602,    47,  5241,    12,\n",
      "         14510,     8,  1357,   441,   997,   716,    13,    19, 17180,     8,\n",
      "         15646,   227,    34,  1204,  5731,   157,    45,  1652,    11,    47,\n",
      "             3,     7,    40,   265,  2726,    30,   569,   783,     5,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "target = tokenizer.batch_encode_plus(\n",
    "    [text], \n",
    "    max_length=150, \n",
    "    pad_to_max_length=True,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([150])\n",
      "tensor([   37,  6863,    13,  3545, 30110,   878,   348,    11,  2043,    76,\n",
      "           65,     3,    52, 17943,    26,   165,   455,    24,   263,    34,\n",
      "        29701,    21,   887,    12,  6177,     3,  9782, 10193,    12,    70,\n",
      "         5069,  6976,    30,     8,  5333,    13,  2922,   157,     7,  6111,\n",
      "          232,  2618,    30,  1660,  4306,    37,  3602,    47,  5241,    12,\n",
      "        14510,     8,  1357,   441,   997,   716,    13,    19, 17180,     8,\n",
      "        15646,   227,    34,  1204,  5731,   157,    45,  1652,    11,    47,\n",
      "            3,     7,    40,   265,  2726,    30,   569,   783,     5,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "----------\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([150])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "target_ids = target[\"input_ids\"].squeeze()\n",
    "\n",
    "print(type(target_ids))\n",
    "print(target_ids.shape)\n",
    "print(target_ids)\n",
    "print(\"-\"*10)\n",
    "\n",
    "target_mask = target[\"attention_mask\"].squeeze()\n",
    "\n",
    "print(type(target_mask))\n",
    "print(target_mask.shape)\n",
    "print(target_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsSummaryDataset():\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        self.text = self.data.text\n",
    "        self.ctext = self.data.ctext\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"text\": self.text, \n",
    "            \"ctext\": self.ctext\n",
    "        }\n",
    "\n",
    "dataset = NewsSummaryDataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4514"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 0       The Administration of Union Territory Daman an...\n",
       " 1       Malaika Arora slammed an Instagram user who tr...\n",
       " 2       The Indira Gandhi Institute of Medical Science...\n",
       " 3       Lashkar-e-Taiba's Kashmir commander Abu Dujana...\n",
       " 4       Hotels in Maharashtra will train their staff t...\n",
       "                               ...                        \n",
       " 4509    Fruit juice concentrate maker Rasna is eyeing ...\n",
       " 4510    Former Indian cricketer Sachin Tendulkar atten...\n",
       " 4511    Aamir Khan, while talking about reality shows ...\n",
       " 4512    The Maharashtra government has initiated an in...\n",
       " 4513    At least 400 languages or more than half langu...\n",
       " Name: text, Length: 4514, dtype: object,\n",
       " 'ctext': 0       summarize: The Daman and Diu administration on...\n",
       " 1       summarize: From her special numbers to TV?appe...\n",
       " 2       summarize: The Indira Gandhi Institute of Medi...\n",
       " 3       summarize: Lashkar-e-Taiba's Kashmir commander...\n",
       " 4       summarize: Hotels in Mumbai and other Indian c...\n",
       "                               ...                        \n",
       " 4509    summarize: Mumbai, Feb 23 (PTI) Fruit juice co...\n",
       " 4510    summarize: Former cricketer Sachin Tendulkar w...\n",
       " 4511    summarize: Aamir Khan, whose last film Dangal ...\n",
       " 4512    summarize: Maharahstra Power Minister Chandras...\n",
       " 4513    summarize: More than half of the languages spo...\n",
       " Name: ctext, Length: 4514, dtype: object}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataframe, \n",
    "        tokenizer, \n",
    "        source_len, \n",
    "        summ_len\n",
    "    ):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.text\n",
    "        self.ctext = self.data.ctext\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [ctext], \n",
    "            max_length=self.source_len, \n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [text], \n",
    "            max_length=self.summ_len, \n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        source_mask = source[\"attention_mask\"].squeeze()\n",
    "        target_ids = target[\"input_ids\"].squeeze()\n",
    "        target_mask = target[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"source_ids\": source_ids.to(dtype=torch.long), \n",
    "            \"source_mask\": source_mask.to(dtype=torch.long), \n",
    "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
    "            \"target_ids_y\": target_ids.to(dtype=torch.long)\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 2\n",
    "MAX_LEN = 512\n",
    "SUMMARY_LEN = 150 \n",
    "\n",
    "training_set = CustomDataset(\n",
    "    df, \n",
    "    tokenizer, \n",
    "    MAX_LEN, \n",
    "    SUMMARY_LEN\n",
    ")\n",
    "    \n",
    "train_params = {\n",
    "    \"batch_size\": TRAIN_BATCH_SIZE,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0\n",
    "}\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    training_set, \n",
    "    **train_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  7.992527008056641\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-bff3ffe1e6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/cat-in-the-dat-ii/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAIN_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    model.train()\n",
    "    for _, data in enumerate(training_loader, 0):\n",
    "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
    "        #print(ids)\n",
    "    \n",
    "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
    "        #print(mask)\n",
    "    \n",
    "        y = data[\"target_ids\"].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        #print(y_ids.shape)\n",
    "        #print(y_ids)\n",
    "    \n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        #print(lm_labels)\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        #print(lm_labels)\n",
    "    \n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask,\n",
    "            decoder_input_ids=y_ids,\n",
    "            lm_labels=lm_labels\n",
    "        )\n",
    "    \n",
    "        loss = outputs[0]\n",
    "    \n",
    "        if _ % 500 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss:  {loss.item()}\")\n",
    "    \n",
    "    \n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=model.parameters(), \n",
    "            lr=LEARNING_RATE\n",
    "        )\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
