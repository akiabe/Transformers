{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 8870, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"I love cats.\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i love cats. [SEP]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2293, 8870, 1012, 102, 2002, 2123, 1005, 1056, 2066, 6077, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"I love cats.\", \"He don't like dogs.\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2293, 8870, 1012, 102], [101, 2002, 2123, 1005, 1056, 2066, 6077, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer([\"I love cats.\", \"He don't like dogs.\"])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2293, 8870, 1012, 102, 2009, 1005, 1055, 3306, 2000, 2033, 1012, 102], [101, 2002, 2123, 1005, 1056, 2066, 6077, 1012, 102, 1045, 2064, 1005, 1056, 3305, 2009, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [\"I love cats.\", \"He don't like dogs.\"], \n",
    "    [\"It's Greek to me.\", \"I can't understand it.\"]\n",
    ")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] i love cats. [SEP] it's greek to me. [SEP]\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2293, 8870, 1012, 102, 2009, 1005, 1055, 3306, 2000, 2033, 1012, 102, 0, 0, 0], [101, 2002, 2123, 1005, 1056, 2066, 6077, 1012, 102, 1045, 2064, 1005, 1056, 3305, 2009, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [\"I love cats.\", \"He don't like dogs.\"], \n",
    "    [\"It's Greek to me.\", \"I can't understand it.\"],\n",
    "    padding=True,\n",
    ")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 2293, 8870, 1012,  102, 2009, 1005, 1055, 3306, 2000, 2033,\n",
       "         1012,  102,    0,    0,    0],\n",
       "        [ 101, 2002, 2123, 1005, 1056, 2066, 6077, 1012,  102, 1045, 2064, 1005,\n",
       "         1056, 3305, 2009, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    [\"I love cats.\", \"He don't like dogs.\"], \n",
    "    [\"It's Greek to me.\", \"I can't understand it.\"],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 2009, 1005, 1055, 3306, 2000, 2033, 1012,  102]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"It's Greek to me.\", return_tensors='pt', padding=True)\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0156,  0.2564, -0.3399,  ..., -0.2428,  0.2830,  0.7544],\n",
       "          [ 0.4662,  0.1092, -0.7984,  ..., -0.2918,  0.2954,  0.4456],\n",
       "          [ 0.5022, -0.1174, -0.0162,  ..., -0.3971,  0.0185,  0.2980],\n",
       "          ...,\n",
       "          [-0.0512,  0.5962, -0.2460,  ...,  0.0019,  0.0570,  1.0659],\n",
       "          [ 0.7567,  0.0346, -0.2691,  ...,  0.1350, -0.5766, -0.4198],\n",
       "          [ 0.8299,  0.1093,  0.0729,  ...,  0.1760, -0.7133, -0.2550]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[-0.9133, -0.3905, -0.7854,  0.8402,  0.6667, -0.1750,  0.8700,  0.2264,\n",
       "          -0.7219, -1.0000, -0.3437,  0.9403,  0.9784,  0.3174,  0.9509, -0.6883,\n",
       "          -0.2414, -0.5943,  0.2957, -0.6338,  0.6895,  0.9999,  0.1177,  0.2967,\n",
       "           0.4354,  0.9831, -0.7207,  0.9372,  0.9545,  0.7353, -0.7154,  0.1956,\n",
       "          -0.9896, -0.0025, -0.8013, -0.9888,  0.3763, -0.6817,  0.1052,  0.1373,\n",
       "          -0.9130,  0.2164,  1.0000, -0.5338,  0.1740, -0.2897, -1.0000,  0.3349,\n",
       "          -0.9019,  0.8719,  0.6830,  0.8410,  0.2382,  0.4272,  0.4843, -0.3936,\n",
       "          -0.2036,  0.0082, -0.2242, -0.5944, -0.6096,  0.3054, -0.7795, -0.9039,\n",
       "           0.8233,  0.7187, -0.0271, -0.1706,  0.0144, -0.0806,  0.8956,  0.0640,\n",
       "          -0.1935, -0.8104,  0.6036,  0.1628, -0.7007,  1.0000, -0.5857, -0.9795,\n",
       "           0.7291,  0.6558,  0.6768, -0.0952,  0.3908, -1.0000,  0.5703,  0.0627,\n",
       "          -0.9902,  0.2121,  0.5475, -0.2501,  0.4184,  0.6636, -0.3298, -0.4124,\n",
       "          -0.3490, -0.7711, -0.1774, -0.2995,  0.0482, -0.1879, -0.2895, -0.3035,\n",
       "           0.2791, -0.4971, -0.5985,  0.6008,  0.1162,  0.6686,  0.5426, -0.3175,\n",
       "           0.3618, -0.9532,  0.6459, -0.2982, -0.9872, -0.6397, -0.9886,  0.5973,\n",
       "          -0.1293, -0.0438,  0.9702, -0.0865,  0.3339, -0.0695, -0.8900, -1.0000,\n",
       "          -0.5962, -0.3622, -0.2811, -0.2167, -0.9768, -0.9655,  0.5440,  0.9676,\n",
       "           0.1440,  0.9998, -0.2322,  0.9471, -0.3117, -0.5669,  0.4971, -0.4434,\n",
       "           0.7188,  0.2087, -0.5839,  0.2163, -0.3955,  0.2362, -0.7177, -0.1636,\n",
       "          -0.6938, -0.9367, -0.3786,  0.9637, -0.4827, -0.8903,  0.1530, -0.2086,\n",
       "          -0.3442,  0.8352,  0.7210,  0.3414, -0.3147,  0.4463,  0.0634,  0.4402,\n",
       "          -0.8598, -0.0598,  0.4042, -0.3915, -0.7025, -0.9792, -0.2753,  0.4710,\n",
       "           0.9880,  0.7784,  0.2456,  0.7584, -0.3500,  0.5765, -0.9555,  0.9826,\n",
       "          -0.0799,  0.2586, -0.2817,  0.4307, -0.8936, -0.2292,  0.8266, -0.6440,\n",
       "          -0.8624,  0.0405, -0.4209, -0.4221, -0.7192,  0.5624, -0.2424, -0.4122,\n",
       "          -0.0068,  0.9393,  0.9785,  0.7825, -0.0870,  0.6570, -0.9179, -0.5051,\n",
       "           0.1022,  0.1286,  0.0447,  0.9944, -0.5315, -0.0534, -0.9491, -0.9866,\n",
       "          -0.0995, -0.9124, -0.1161, -0.7084,  0.5602, -0.3765,  0.4447,  0.3767,\n",
       "          -0.9891, -0.8187,  0.3890, -0.3628,  0.3659, -0.2428,  0.8314,  0.9079,\n",
       "          -0.6022,  0.7284,  0.9133, -0.8352, -0.7759,  0.8234, -0.3036,  0.9044,\n",
       "          -0.5708,  0.9916,  0.8743,  0.7789, -0.9062, -0.5370, -0.9232, -0.5933,\n",
       "          -0.0113, -0.0514,  0.8272,  0.7213,  0.4703,  0.5602, -0.4898,  0.9982,\n",
       "          -0.8543, -0.9654,  0.0195, -0.2241, -0.9887,  0.7996,  0.1208,  0.3082,\n",
       "          -0.4177, -0.6558, -0.9560,  0.8981,  0.1201,  0.9914, -0.3239, -0.9174,\n",
       "          -0.6579, -0.9257, -0.1545, -0.2169, -0.2663, -0.1618, -0.9580,  0.4738,\n",
       "           0.5694,  0.5161, -0.7559,  0.9986,  1.0000,  0.9728,  0.9003,  0.8992,\n",
       "          -0.9996, -0.5848,  1.0000, -0.9888, -1.0000, -0.9406, -0.6336,  0.3959,\n",
       "          -1.0000, -0.1883,  0.1365, -0.8833,  0.4950,  0.9786,  0.9943, -1.0000,\n",
       "           0.8483,  0.9627, -0.6971,  0.9384, -0.3724,  0.9726,  0.6319,  0.4251,\n",
       "          -0.2796,  0.3206, -0.8793, -0.8332, -0.4240, -0.6908,  0.9976,  0.0605,\n",
       "          -0.7447, -0.8977,  0.5059,  0.0166, -0.2569, -0.9637, -0.1751,  0.2564,\n",
       "           0.7305,  0.1596,  0.2052, -0.6957,  0.1574, -0.1314,  0.1916,  0.7193,\n",
       "          -0.9377, -0.7069, -0.0684, -0.2128, -0.4344, -0.9657,  0.9625, -0.3562,\n",
       "           0.7799,  1.0000,  0.1778, -0.8864,  0.6476,  0.2633, -0.4683,  1.0000,\n",
       "           0.8107, -0.9798, -0.6867,  0.6715, -0.5306, -0.6274,  0.9991, -0.2605,\n",
       "          -0.4715, -0.2894,  0.9759, -0.9902,  0.9931, -0.9362, -0.9716,  0.9623,\n",
       "           0.9441, -0.3887, -0.6805,  0.0801, -0.6213,  0.2505, -0.9667,  0.7797,\n",
       "           0.4757, -0.0036,  0.9184, -0.8641, -0.6875,  0.3182, -0.6563,  0.0765,\n",
       "           0.8917,  0.5183, -0.2402, -0.0083, -0.1264, -0.5404, -0.9762,  0.5888,\n",
       "           1.0000, -0.1223,  0.6860, -0.4643,  0.0412, -0.2458,  0.4592,  0.5343,\n",
       "          -0.2805, -0.8193,  0.7224, -0.9690, -0.9873,  0.7782,  0.1584, -0.2425,\n",
       "           1.0000,  0.2071,  0.2039,  0.2510,  0.9703, -0.0605,  0.4245,  0.7112,\n",
       "           0.9842, -0.1561,  0.6815,  0.9079, -0.8460, -0.2523, -0.6812, -0.0952,\n",
       "          -0.9206,  0.1236, -0.9608,  0.9660,  0.8707,  0.3780,  0.1155,  0.5427,\n",
       "           1.0000, -0.2623,  0.5858, -0.2962,  0.8350, -0.9996, -0.8454, -0.3646,\n",
       "           0.0560, -0.7483, -0.3201,  0.1983, -0.9702,  0.6820,  0.5380, -0.9884,\n",
       "          -0.9849, -0.0916,  0.8281,  0.0182, -0.9769, -0.7397, -0.6438,  0.5224,\n",
       "          -0.2736, -0.9324,  0.0395, -0.3205,  0.5291, -0.1689,  0.6447,  0.7603,\n",
       "           0.7760, -0.6414, -0.2018,  0.0424, -0.7970,  0.8753, -0.8562, -0.8956,\n",
       "          -0.0926,  1.0000, -0.5958,  0.7470,  0.7382,  0.7780, -0.1969,  0.1019,\n",
       "           0.8969,  0.1907, -0.5858, -0.7944, -0.5117, -0.3439,  0.7038,  0.3958,\n",
       "           0.6087,  0.7944,  0.6518,  0.0853,  0.0828,  0.0102,  0.9996, -0.1484,\n",
       "          -0.2130, -0.5994,  0.0168, -0.2937, -0.2072,  1.0000,  0.2520,  0.1183,\n",
       "          -0.9907, -0.7155, -0.9347,  1.0000,  0.8109, -0.8246,  0.6625,  0.4372,\n",
       "          -0.1669,  0.7677, -0.1166, -0.1195,  0.1704,  0.0023,  0.9554, -0.5448,\n",
       "          -0.9648, -0.3760,  0.3842, -0.9591,  0.9997, -0.5595, -0.2237, -0.3102,\n",
       "          -0.2759,  0.4536, -0.1576, -0.9844, -0.1526,  0.0904,  0.9727,  0.1821,\n",
       "          -0.6876, -0.9202,  0.7507,  0.6014, -0.8244, -0.9212,  0.9563, -0.9819,\n",
       "           0.6484,  1.0000,  0.3530, -0.0714,  0.1917, -0.5182,  0.2928,  0.0620,\n",
       "           0.6832, -0.9668, -0.3790, -0.0697,  0.2953, -0.1636, -0.0742,  0.5359,\n",
       "           0.1259, -0.6366, -0.6104, -0.1029,  0.4068,  0.8402, -0.1597, -0.0776,\n",
       "           0.1683, -0.1982, -0.9053, -0.3687, -0.4731, -1.0000,  0.6780, -1.0000,\n",
       "           0.5127, -0.0287, -0.1745,  0.8279,  0.6478,  0.7101, -0.7182, -0.8061,\n",
       "           0.5089,  0.7792, -0.2286, -0.2772, -0.7386,  0.2795,  0.0225,  0.2550,\n",
       "          -0.5458,  0.7495, -0.2950,  1.0000,  0.0343, -0.6274, -0.9783,  0.1480,\n",
       "          -0.2933,  1.0000, -0.9432, -0.9449,  0.2910, -0.7213, -0.8242,  0.2827,\n",
       "          -0.0546, -0.7314, -0.8746,  0.9608,  0.8436, -0.6946,  0.5004, -0.2363,\n",
       "          -0.5347, -0.0867,  0.8307,  0.9869,  0.3385,  0.9270, -0.2144, -0.2056,\n",
       "           0.9711,  0.2476,  0.4847,  0.0930,  1.0000,  0.2445, -0.9068,  0.3121,\n",
       "          -0.9896,  0.0247, -0.9644,  0.2723,  0.1241,  0.9203, -0.2194,  0.9507,\n",
       "          -0.6062, -0.0486, -0.4945, -0.3515,  0.3547, -0.9363, -0.9836, -0.9831,\n",
       "           0.6287, -0.4047,  0.0129,  0.2955,  0.0655,  0.4408,  0.3720, -1.0000,\n",
       "           0.9449,  0.4126,  0.7952,  0.9684,  0.6972,  0.5452,  0.2317, -0.9867,\n",
       "          -0.9882, -0.2759, -0.2724,  0.7991,  0.7224,  0.8751,  0.3871, -0.4907,\n",
       "          -0.5682, -0.4315, -0.8183, -0.9929,  0.3623, -0.5781, -0.9665,  0.9568,\n",
       "          -0.3484, -0.0198,  0.0408, -0.7732,  0.9303,  0.7688,  0.3027,  0.0106,\n",
       "           0.4759,  0.8750,  0.9343,  0.9809, -0.7242,  0.7990, -0.7849,  0.4266,\n",
       "           0.4060, -0.9352,  0.1385,  0.4378, -0.2075,  0.1866, -0.1994, -0.9795,\n",
       "           0.2146, -0.1841,  0.5389, -0.3165,  0.1313, -0.3260, -0.2117, -0.6762,\n",
       "          -0.6814,  0.7192,  0.3206,  0.8954,  0.8185,  0.0314, -0.7435, -0.0809,\n",
       "          -0.7153, -0.8941,  0.9390,  0.0656, -0.2072,  0.5368, -0.1066,  0.7737,\n",
       "          -0.1126, -0.3245, -0.3391, -0.7445,  0.8984, -0.6102, -0.5024, -0.5232,\n",
       "           0.6022,  0.2469,  0.9999, -0.6179, -0.8350, -0.5093, -0.3404,  0.3294,\n",
       "          -0.4048, -1.0000,  0.3791, -0.6001,  0.5018, -0.5733,  0.7207, -0.7161,\n",
       "          -0.9735, -0.0778,  0.2258,  0.7220, -0.4573, -0.5950,  0.6663, -0.3920,\n",
       "           0.9652,  0.9020, -0.5321,  0.2908,  0.7461, -0.7285, -0.6789,  0.9270]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}